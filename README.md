# EECS4461: AI Undercover

# Overview:
The research investigates AI cheating bots and anti-cheat systems that operate within the Slither.io online multiplayer game. This research examines the impact these artificial intelligences have on digital trust along with game mechanical fairnes.

## Game Environment:
* **Game:** Slither.io involves playing as a snake character to consume pellets and grow longer
* **Cheating Bots:** Use advanced techniques to articially boost growth, gaining an unfair advantage
* **Anti-Cheat System:** Monitor growth patterns to identify and flag suspicious behaviour

## Importance of AI-to-AI Interactions:
* **Balance:** The detection system needs proper balance to prevent cheating detection effectiveness from harming legitimate players
* **Trust & Fairness:** The continuous detection of cheating results in a loss of user confidence which damages digital economic performance

## Research Methodology:
* **Agent-Based Modeling (ABM):** Enables the simulation of complex interactions that occur between different agents which include players and both cheat detectors and cheating bots
* **Phases of Simulation:** The simulation progresses across multiple phases which are displayed through comics demonstrating player detection methods step by step


# Simulation Design & Implementation
The project offers a simulated environment that evaluates the interactions between players and AI cheat bots and AI cheat detection bots under Slither.io-like game rules for observing emergent AI behaviors and their effects on game equity along with digital trust abilities.

## Key Components:
### Environment:
* The versioned toroidal area of the game space eliminates spatial constraints and duplicates open-world game environments by being endless
* The agents possess distinctive speeds along with different detection ranges which produces an evolving and competitive environment during the simulation

### Simulation Dynamics:
* A simulation began with established player numbers of regular players and detectors alongside cheat bots
* RandomActivation from Mesa allows the simulation of ingame events that occur unpredictably in real time
* Focuses on proximity and score-based cheat detection, with adaptability in cheat bots to evade detection

### Data Handling & Visualization:
* The system displays tracking data for scores and flags together with detection accuracy through scatter plots and time-series graphs
* Analysis through real-time data visualization helps to track changes in the detection capabilities of the system through visualization

# Observation & Results:
A simulation modeling permits research into AI cheat bots and anti-cheat system relationships within an environment based on Slither.io while studying the evolution of advanced artificial intelligence behaviors throughout cheating and detection. The simulation begins with three component groups including regular players and cheat bots alongside detectors which allows tracking of advanced cheating techniques and improved detection capabilities. The research demonstrates that cheat bots change their methods to decrease detection possibilities which demonstrates the necessity of advancing detection systems. Adaptive anti-cheat mechanisms remain critical for ensuring digital gaming fairness based on the analysis presented.

# Ethical & Societal Reflections
* **Data Privacy:** Synthetic data served as the main tool to safeguard privacy while stopping unnecessary personal information exposure
* **False Positives:** The false positive issue required researchers to address ethical problems of misidentifying genuine players as cheaters which emphasized the requirement for better detection systems
* **Balanncing Fairness:** The implementation of detection systems needs to find a fair balance between strict enforcement and fairness since both aspects contribute to user trust and platform ethical integrity
* **Ethical Development:** The importance of developing ethical AI during gameplay required emphasis according to experts


# Lessons Learned & Future Directions
* **Technical Challenges:** System performance declined when trying to embed realistic behaviors at a level that did not affect computational efficiency which caused processing delays and system lag. The model achieved better results because the team optimized frequencies of updates along with deploying advanced data structures
* **Conceptual Challenges:** I experienced difficulty at first with the fundamental evasion methods used by cheat bots during this phase. The system improves its authenticity through the implementation of adaptive algorithms which let bots make behavioral modifications when they face detection pressure
* **Detection Calibration:** The team experienced measurement calibration problems with cheat detection sensitivity which resulted in numerous false positive detections. A sliding numerical score system with automatic thresholds helped detect genuine high achievers from cheaters accurately

## Model Limitations & Areas for Improvement:
* **Player Behaviour:** The model restricts player actions by omitting the strategic coordination which identifies true human participants. The following versions plan to include sophisticated human behaviors which will boost realism throughout the simulation
* **Social Interactions:** The current model fails to reproduce community-based moderation since it ignores player teamwork for detecting cheating players. The developers plan to include functionality which enables players to work together for spotting and reporting unusual conduct throughout the game
* **Scoring and Flagging Enhancements:** New scoring and flagging enhancements should be added through adaptive bots which use machine learning to understand pattern changes in order to boost detection efficiency

## Future Applications:
* **Platform Governance and AI Safety:** Analysis of the simulation should facilitate development of adaptable cheating detection methods which platform moderators and game developers can use for their platforms
* **Broader Applications:** Our system model can apply to multiple online environments beyond Facebook like social networks and cybersecurity platforms that fight AI cybersecurity threats
* **Policy Implications:** Simulation results can inform policymaking, ensuring security measures are balanced with user rights protection and maintaining platform credibility


# Team members:
* Adil Guluzade
* Santusht Arora
* Faraz Akbarzadeh


# References
* Chen, M. (2024). “AI cheating versus AI anti-cheating: A technological battle in game,” Applied and Computational Engineering, vol. 73, no. 1, pp. 222–227. https://doi.org/10.54254/2755-2721/73/20240402
* Skinner, G. & Walmsley, T. (2019). “Artificial intelligence and deep learning in video games: A brief review,” in 2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS), pp. 404–408. https://doi.org/10.1109/CCOMS.2019.8821783
* Arai, K., Deguchi, H., & Matsui, H. “Agent-based modeling meets gaming simulation,” ResearchGate. https://www.researchgate.net/publication/321596055_Agent-Based_Modeling_Meets_Gaming_Simulation
* Lehtonen, M. J., Vesa, M., & Harviainen, J. T. (2022). “Games-as-a-disservice: Emergent value co-destruction in platform business models,” Journal of Business Research, vol. 141, pp. 564–574. https://doi.org/10.1016/j.jbusres.2021.11.055
* Jonnalagadda, A., Frosio, I., Schneider, S., McGuire, M., & Kim, J. (2021). “Robust vision-based cheat detection in competitive gaming,” Proceedings of the ACM on Computer Graphics and Interactive Techniques, vol. 4, no. 1, pp. 1–18. https://doi.org/10.1145/3451259
